{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3589513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.predictor import Predictor\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import joblib  # For saving the scaler if needed\n",
    "\n",
    "# --- 1. Load Data from S3 ---\n",
    "s3_path = 's3://imba-chien-data-features-dev/features/train/'\n",
    "train_df = pd.read_parquet(s3_path)\n",
    "print(\"Loaded data shape:\", train_df.shape)\n",
    "\n",
    "# --- 2. Prepare Data: Label as first column ---\n",
    "X = train_df.drop(columns=[\"user_id\", \"product_id\", \"reordered\"])\n",
    "y = train_df[\"reordered\"]\n",
    "\n",
    "# --- 2a. Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Feature scaling complete. Mean (should be ~0):\", X_scaled.mean(axis=0))\n",
    "\n",
    "# (Optional) Save the scaler for inference use\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "# Upload scaler.pkl to S3 if you want to use it in Lambda or elsewhere\n",
    "bucket = \"imba-chien-data-features-dev\"\n",
    "scaler_s3_key = \"scale_models/scaler.pkl\"\n",
    "boto3.client('s3').upload_file(\"scaler.pkl\", bucket, scaler_s3_key)\n",
    "print(f\"Uploaded scaler to s3://{bucket}/{scaler_s3_key}\")\n",
    "\n",
    "# --- 2b. Combine label and scaled features ---\n",
    "train_data = np.column_stack((y, X_scaled))\n",
    "train_df_sagemaker = pd.DataFrame(train_data)\n",
    "\n",
    "# --- 3. Save as Parquet (no header, no index) ---\n",
    "local_parquet = 'train_sagemaker.parquet'\n",
    "train_df_sagemaker.to_parquet(local_parquet, index=False)\n",
    "print(f\"Saved local parquet: {local_parquet}\")\n",
    "\n",
    "# --- 4. Upload to S3 ---\n",
    "bucket = 'imba-chien-data-features-dev'\n",
    "s3_key = 'sagemaker/train.parquet'\n",
    "boto3.client('s3').upload_file(local_parquet, bucket, s3_key)\n",
    "print(f\"Uploaded to s3://{bucket}/{s3_key}\")\n",
    "\n",
    "# --- 5. Set up SageMaker Training Job ---\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "prefix = 'xgboost-model'\n",
    "output_path = f's3://{bucket}/{prefix}/output'\n",
    "\n",
    "hyperparameters = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": 7,\n",
    "    \"eta\": 0.2,\n",
    "    \"eval_metric\": \"logloss,auc\",\n",
    "    \"num_round\": 1000,\n",
    "    \"early_stopping_rounds\": 20\n",
    "}\n",
    "\n",
    "xgboost_container = image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_container,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# --- 6. Define Training Input ---\n",
    "train_input = TrainingInput(\n",
    "    f's3://{bucket}/sagemaker/train.parquet',\n",
    "    content_type='application/x-parquet'\n",
    ")\n",
    "\n",
    "# --- 7. Launch Training Job ---\n",
    "print(\"Starting SageMaker training job...\")\n",
    "estimator.fit({'train': train_input})\n",
    "print(\"Training job launched.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f6cb8",
   "metadata": {},
   "source": [
    "# Deploy Endpoint for Inference\n",
    "### We will deploy endpoint by Terraform, so the following is for test only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc168d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Deploy Endpoint ---\n",
    "print(\"Deploying endpoint...\") \n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "# Delete the endpoint (if it exists)\n",
    "try:\n",
    "    sm.delete_endpoint(EndpointName='xgboost-endpoint')\n",
    "except sm.exceptions.ClientError:\n",
    "    pass  # Already deleted\n",
    "\n",
    "# Delete the endpoint configuration\n",
    "try:\n",
    "    sm.delete_endpoint_config(EndpointConfigName='xgboost-endpoint')\n",
    "except sm.exceptions.ClientError:\n",
    "    pass  # Already deleted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',  # or another supported instance type\n",
    "    endpoint_name='xgboost-endpoint'  # optional: custom endpoint name\n",
    ")\n",
    "print(\"Endpoint deployed.\")\n",
    "\n",
    "# --- 9. Test Endpoint ---\n",
    "print(\"Testing endpoint...\")\n",
    "\n",
    "predictor = Predictor(endpoint_name='xgboost-endpoint')\n",
    "\n",
    "s3_path = 's3://imba-chien-data-features-dev/features/test/'\n",
    "test_df = pd.read_parquet(s3_path)\n",
    "\n",
    "X_test = test_df.drop(columns=[\"user_id\", \"product_id\"])\n",
    "print(X_test.columns)\n",
    "# Index(['user_orders_scaled', 'user_periods_scaled',\n",
    "#        'user_mean_days_since_prior_scaled', 'user_products_scaled',\n",
    "#        'user_distinct_products_scaled', 'user_reorder_ratio_scaled',\n",
    "#        'prod_orders_scaled', 'prod_reorders_scaled',\n",
    "#        'prod_first_orders_scaled', 'prod_second_orders_scaled'],\n",
    "#       dtype='object')\n",
    "\n",
    "sample = X_test.iloc[0].values.reshape(1, -1)\n",
    "csv_str = ','.join(str(x) for x in sample[0]) + '\\n'\n",
    "response = predictor.predict(csv_str, initial_args={'ContentType': 'text/csv'})\n",
    "print(\"Prediction:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
